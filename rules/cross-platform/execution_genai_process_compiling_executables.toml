[metadata]
creation_date = "2025/11/19"
integration = ["endpoint"]
maturity = "production"
updated_date = "2025/11/19"

[rule]
author = ["Elastic"]
description = """
Detects when well-known Generative AI (GenAI) tools and frameworks launch compilation or packaging tools (gcc, clang,
msbuild, pyinstaller, etc.) to generate executables. This rule focuses specifically on GenAI desktop applications
(Ollama, LM Studio, Claude Desktop, Cursor, GitHub Copilot) and GenAI frameworks (AutoGPT, LangChain, MCP servers,
etc.). Attackers increasingly leverage local LLMs to generate executable code (malware prototypes, droppers, credential
harvesters, backdoors) and then compile that code into executables for deployment. This technique allows attackers to
rapidly prototype and generate polymorphic malware variants using AI assistance. Typical local AI tools rarely compile
binaries automatically and rarely do so non-user driven, non-interactive environments. Malicious actors may use GenAI
to generate obfuscated or encoded payloads, create custom tools for lateral movement, or develop malware for evasion.
"""
from = "now-9m"
index = ["logs-endpoint.events.*"]
language = "eql"
license = "Elastic License v2"
name = "GenAI Process Compiling or Generating Executables"
note = """## Triage and analysis

### Investigating GenAI Process Compiling or Generating Executables

GenAI processes launching compilers or packaging tools is highly suspicious. Legitimate AI tools rarely compile binaries automatically, and when they do, it's typically user-driven and interactive. This behavior strongly indicates malicious activity where AI tools are being used to generate and compile malware.

### Possible investigation steps

- Review the GenAI process that spawned the compiler to identify which tool is running and verify if it's an expected/authorized tool.
- Investigate the user account associated with the GenAI process to determine if this activity is expected for that user.
- Review the output files created by the compilation process to identify any malicious executables.
- Check for other alerts or suspicious activity on the same host around the same time.
- Verify if the GenAI tool is from a trusted source and if it's authorized for use in your environment.
- Identify whether the generated executables appear in temporary directories often used for malware staging (`%TEMP%`, `/tmp`, `.cache`).
- Inspect the compiled artifacts for networking imports, credential harvesting functionality, or persistence mechanisms.

### False positive analysis

- Legitimate development workflows that use GenAI tools for code generation may trigger this rule if they compile the generated code.
- Some GenAI-assisted coding IDEs (Cursor, Copilot Workspace) may run compilation tasks when testing code; confirm whether the behavior is tied to developer workflow.

### Response and remediation

- Terminate the GenAI process and any spawned compiler processes to stop the malicious activity.
- Investigate the compiled executables to determine if they are malicious.
- Review audit logs to determine the scope of compilation activity and identify any executables that may have been created.
- Quarantine any compiled binaries; submit suspicious artifacts to sandbox or malware analysis.
"""
references = [
  "https://atlas.mitre.org/techniques/AML.T0053",
  "https://www.elastic.co/security-labs/elastic-advances-llm-security"
]
risk_score = 73
rule_id = "b2c3d4e5-f6a7-8901-bcde-f123456789ab"
severity = "high"
tags = [
    "Domain: Endpoint",
    "OS: Linux",
    "OS: macOS",
    "OS: Windows",
    "Use Case: Threat Detection",
    "Tactic: Execution",
    "Tactic: Defense Evasion",
    "Data Source: Elastic Defend",
    "Resources: Investigation Guide",
    "Domain: LLM",
    "Mitre Atlas: T0053",
]
timestamp_override = "event.ingested"
type = "eql"
query = '''
process where event.type == "start" and event.action in ("exec", "executed", "process_started", "start", "ProcessRollup2") and
  // GenAI-related parent process: native GenAI executables OR node/python/deno with GenAI indicators in command line
  (
    // Native GenAI executables
    process.parent.name in ("ollama.exe", "ollama", "textgen.exe", "textgen", "lmstudio.exe", "lmstudio", "claude.exe", "claude", "cursor.exe", "cursor", "copilot.exe", "copilot", "gemini-cli.exe", "gemini-cli", "genaiscript.exe", "genaiscript", "grok.exe", "grok", "qwen.exe", "qwen") or

    // Node/Deno processes with GenAI frameworks in command line
    (process.parent.name in ("node.exe", "node", "deno.exe", "deno") and
     process.parent.command_line like~ ("*mcp-server*", "*@modelcontextprotocol*", "*mcp run*", "*mcp_*", "*langchain*", "*autogpt*", "*babyagi*", "*agentgpt*", "*crewai*", "*semantic-kernel*", "*llama-index*", "*haystack*", "*transformers*", "*claude*", "*copilot*", "*cursor*", "*gemini*", "*genaiscript*", "*grok*", "*qwen*")) or

    // Python processes with GenAI frameworks in command line
    (process.parent.name like~ "python*" and
     process.parent.command_line like~ ("*langchain*", "*autogpt*", "*babyagi*", "*agentgpt*", "*crewai*", "*semantic-kernel*", "*llama-index*", "*haystack*", "*transformers*", "*claude*", "*copilot*", "*cursor*", "*gemini*", "*genaiscript*", "*grok*", "*qwen*"))
  ) and

  // Compilation or packaging tools
  (
    process.name in ("gcc", "g++", "clang", "clang++", "cl.exe", "cl", "make", "cmake", "msbuild.exe", "dotnet", "go", "rustc", "cargo", "pyinstaller", "py2exe", "cx_Freeze", "nuitka", "pyarmor", "pkg", "fpm", "dpkg-deb", "csc.exe", "vbc.exe", "javac", "jar") or
    process.command_line like~ ("*msbuild*", "*dotnet build*", "*go build*", "*cargo build*", "*pyinstaller*", "*py2exe*", "*nuitka*", "*pyarmor*")
  ) and

  // Exclude version checks, help commands, and git operations
  not (
    process.command_line like~ ("*git*") or
    process.name == "git" or
    process.command_line like~ ("*--version*", "*--help*") or
    process.args in ("--version", "--help")
  )
'''

[[rule.threat]]
framework = "MITRE ATLAS"

  [rule.threat.tactic]
  name = "Execution"
  id = "AML.TA0005"
  reference = "https://atlas.mitre.org/tactics/AML.TA0005/"

  [[rule.threat.technique]]
  name = "AI Agent Tool Invocation"
  id = "AML.T0053"
  reference = "https://atlas.mitre.org/techniques/AML.T0053/"

[[rule.threat]]
framework = "MITRE ATT&CK"

  [rule.threat.tactic]
  name = "Defense Evasion"
  id = "TA0005"
  reference = "https://attack.mitre.org/tactics/TA0005/"

  [[rule.threat.technique]]
  name = "Obfuscated Files or Information"
  id = "T1027"
  reference = "https://attack.mitre.org/techniques/T1027/"

    [[rule.threat.technique.subtechnique]]
    name = "Compile After Delivery"
    id = "T1027.004"
    reference = "https://attack.mitre.org/techniques/T1027/004/"

