[metadata]
creation_date = "2026/02/23"
integration = ["endpoint"]
maturity = "development"
updated_date = "2026/02/23"

[rule]
author = ["Elastic"]
description = """
Detects the first time a Python process accesses sensitive credential files on a given host. Malicious pickle or
PyTorch model files can execute arbitrary code during deserialization that reads SSH keys, AWS credentials, browser
cookies, Kerberos tickets, or keychain databases. Legitimate Python scripts in data science environments do not
typically access these files, so a first occurrence is a strong indicator of compromise via malicious model loading
or post-exploitation activity.
"""
from = "now-9m"
index = ["logs-endpoint.events.file-*"]
language = "kuery"
license = "Elastic License v2"
name = "First Time Python Accessed Sensitive Credential Files"
note = """## Triage and analysis

### Investigating First Time Python Accessed Sensitive Credential Files

When Python loads a malicious pickle or PyTorch model, the `__reduce__` deserialization method can execute arbitrary code including reading sensitive credential files. This technique is used by attackers to steal SSH keys, cloud provider credentials, browser session cookies, and macOS keychain data. Since legitimate data science workflows do not access these files, a first occurrence from a Python process is highly suspicious.

This rule leverages the Elastic Defend sensitive file `open` event, which is only collected for known sensitive file paths, combined with the New Terms rule type to alert on the first time a specific credential file is accessed by Python on a given host within a 7-day window.

### Possible investigation steps

- Examine the Python process command line and arguments to identify the script or command that triggered the file access.
- Determine if the Python process was loading a model file by looking for `torch.load`, `pickle.load`, or similar calls.
- Review the specific credential file that was accessed and assess the potential impact (SSH keys enable lateral movement, AWS credentials enable cloud access, browser cookies enable session hijacking).
- Check for outbound network connections from the same process tree that may indicate credential exfiltration.
- Investigate the origin of any model files recently downloaded or modified on the host.
- Look for file creation events in `/tmp/` or other staging directories that may contain copies of the stolen credentials.

### False positive analysis

- Python-based secret management tools (e.g., `aws-cli`, `gcloud`) legitimately access credential files. Consider excluding known trusted executables by process path.
- SSH automation scripts using `paramiko` or `fabric` may read SSH keys. Evaluate whether the access pattern matches known automation workflows.
- Security scanning tools running Python may enumerate credential files as part of their assessment.

### Response and remediation

- Immediately rotate any credentials that were potentially accessed (SSH keys, AWS access keys, cloud tokens).
- Quarantine the Python process and investigate the source model or script that triggered the access.
- If a malicious model file is confirmed, identify all hosts where it was distributed.
- Review outbound network connections from the host around the time of the credential access to check for exfiltration.
- Consider implementing `weights_only=True` enforcement for PyTorch model loading across the environment.
"""
references = [
    "https://blog.trailofbits.com/2024/06/11/exploiting-ml-models-with-pickle-file-attacks-part-1/",
    "https://github.com/trailofbits/fickling",
]
risk_score = 47
rule_id = "03b150d9-9280-4eb8-9906-38cfb6184666"
severity = "medium"
tags = [
    "Domain: Endpoint",
    "OS: macOS",
    "Use Case: Threat Detection",
    "Tactic: Credential Access",
    "Data Source: Elastic Defend",
    "Resources: Investigation Guide",
    "Domain: LLM",
]
timestamp_override = "event.ingested"
type = "new_terms"
query = '''
event.category:file and host.os.type:macos and event.action:open and
process.name:(python or python3 or python3.* or Python)
'''

[[rule.threat]]
framework = "MITRE ATT&CK"
[[rule.threat.technique]]
id = "T1555"
name = "Credentials from Password Stores"
reference = "https://attack.mitre.org/techniques/T1555/"
[[rule.threat.technique.subtechnique]]
id = "T1555.001"
name = "Keychain"
reference = "https://attack.mitre.org/techniques/T1555/001/"

[rule.threat.tactic]
id = "TA0006"
name = "Credential Access"
reference = "https://attack.mitre.org/tactics/TA0006/"

[rule.new_terms]
field = "new_terms_fields"
value = ["host.id", "file.path"]
[[rule.new_terms.history_window_start]]
field = "history_window_start"
value = "now-7d"
